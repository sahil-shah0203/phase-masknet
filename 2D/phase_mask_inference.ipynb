{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7480b545",
   "metadata": {},
   "source": [
    "\n",
    "# Phase Mask Inference (PhaseMaskNet)\n",
    "\n",
    "## Purpose\n",
    "Load a pre-trained PhaseMaskNet model and predict phase masks for given cross-section images without retraining.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d6a2b3",
   "metadata": {},
   "source": [
    "\n",
    "## Setup\n",
    "- Install necessary packages (`torch`, `PIL`, `matplotlib`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c26220",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install piq\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dde55af",
   "metadata": {},
   "source": [
    "\n",
    "## Load Trained Model\n",
    "- Define PhaseMaskNet model.\n",
    "- Load saved weights from `.pth` file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5050e42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class PhaseMaskNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1, features=[32, 64, 128]):\n",
    "        super(PhaseMaskNet, self).__init__()\n",
    "        self.encoder1 = DoubleConv(in_channels, features[0])\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.encoder2 = DoubleConv(features[0], features[1])\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.bottleneck = DoubleConv(features[1], features[2])\n",
    "\n",
    "        self.upconv2 = nn.ConvTranspose2d(features[2], features[1], kernel_size=2, stride=2)\n",
    "        self.decoder2 = DoubleConv(features[2], features[1])\n",
    "\n",
    "        self.upconv1 = nn.ConvTranspose2d(features[1], features[0], kernel_size=2, stride=2)\n",
    "        self.decoder1 = DoubleConv(features[1], features[0])\n",
    "\n",
    "        self.conv_final = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.pool1(enc1))\n",
    "\n",
    "        bottleneck = self.bottleneck(self.pool2(enc2))\n",
    "\n",
    "        dec2 = self.upconv2(bottleneck)\n",
    "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "\n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
    "        dec1 = self.decoder1(dec1)\n",
    "\n",
    "        return self.conv_final(dec1)\n",
    "\n",
    "# Initialize and load weights\n",
    "model = PhaseMaskNet().to(device)\n",
    "model.load_state_dict(torch.load('/content/phase_mask_net.pth', map_location=device))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20e3fcb",
   "metadata": {},
   "source": [
    "\n",
    "## Predict and Visualize\n",
    "- Load an image, predict phase mask, and visualize.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb07adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_image(path, size=128):\n",
    "    img = Image.open(path).convert('L')\n",
    "    img = img.resize((size, size))\n",
    "    img = np.array(img, dtype=np.float32) / 255.0\n",
    "    img = torch.from_numpy(img).unsqueeze(0).unsqueeze(0)  # (1, 1, H, W)\n",
    "    return img.to(device)\n",
    "\n",
    "# Example: Replace path with your test image\n",
    "image_path = '/content/drive/MyDrive/slices/slice_001.png'  # Example path\n",
    "img = load_image(image_path)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = model(img)\n",
    "\n",
    "# Plot input and prediction\n",
    "input_img = img.squeeze().cpu().numpy()\n",
    "pred_img = pred.squeeze().cpu().numpy()\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "axs[0].imshow(input_img, cmap='gray')\n",
    "axs[0].set_title('Input Slice')\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].imshow(pred_img, cmap='gray')\n",
    "axs[1].set_title('Predicted Phase Mask')\n",
    "axs[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16b0a9e",
   "metadata": {},
   "source": [
    "\n",
    "## Notes\n",
    "- Ensure model input resolution matches what it was trained on (e.g., 128Ã—128).\n",
    "- For future deployments, consider wrapping the model into a simple API or serverless function.\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
